{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MdXy31L9lVDo",
        "outputId": "c67ffd3f-b60e-44f4-ba8f-fcabaa441f24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/327.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m327.7/327.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.7/327.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -qU langchain-qdrant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kCdil1sEljWT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass # Import the getpass module\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = userdata.get(\"LANGSMITH_API_KEY\")\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "NXv1B57QouEm",
        "outputId": "38742c31-350f-4575-af6b-b139b89fa490"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/62.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.2 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "pip install -qU langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sWKLJNZKozRF"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "  os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "collapsed": true,
        "id": "M6rUmRYTvHtB"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain-community\n",
        "\n",
        "\"\"\"\n",
        "This code snippet installs necessary components and sets up tools\n",
        "for converting text into numerical representations (embeddings)\n",
        "using a powerful pre-trained model from Hugging Face.\n",
        "These embeddings can then be used for various tasks, such as\n",
        "semantic similarity search, text classification, and clustering.\n",
        "\"\"\"\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "e8A8EAWhq1gx"
      },
      "outputs": [],
      "source": [
        "from langchain_qdrant import QdrantVectorStore\n",
        "from qdrant_client import QdrantClient\n",
        "\n",
        "\"\"\"\n",
        "this code block sets up a connection to a Qdrant vector\n",
        "database, prepares to store documents there as vectors\n",
        "using the Hugging Face embeddings model and creates an\n",
        "empty list to fill with documents in further steps.\n",
        "\"\"\"\n",
        "url = userdata.get(\"QDRANT_URL\")\n",
        "api_key = userdata.get(\"QRANT_API_KEY\")\n",
        "docs = []  # put docs here\n",
        "qdrant = QdrantVectorStore.from_documents(\n",
        "    docs,\n",
        "    embeddings,\n",
        "    url=url,\n",
        "    api_key=api_key,\n",
        "    prefer_grpc=True,\n",
        "    collection_name=\"my_documents\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MzRHlhtBArX"
      },
      "outputs": [],
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "\"\"\"\n",
        "Below are sample information on documents for our\n",
        "understanding which we will insert into database\n",
        "\"\"\"\n",
        "document_1 = Document(\n",
        "    page_content=\"I had chocalate chip pancakes and scrambled potatoes for breakfast this morning.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_2 = Document(\n",
        "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_3 = Document(\n",
        "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_4 = Document(\n",
        "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_5 = Document(\n",
        "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_6 = Document(\n",
        "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        ")\n",
        "\n",
        "document_7 = Document(\n",
        "    page_content=\"The top 10 soccer players in the world right now.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        ")\n",
        "\n",
        "document_8 = Document(\n",
        "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_9 = Document(\n",
        "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_10 = Document(\n",
        "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "documents = [\n",
        "    document_1,\n",
        "    document_2,\n",
        "    document_3,\n",
        "    document_4,\n",
        "    document_5,\n",
        "    document_6,\n",
        "    document_7,\n",
        "    document_8,\n",
        "    document_9,\n",
        "    document_10,\n",
        "]\n",
        "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
        "\n",
        "qdrant.add_documents(documents=documents, ids=uuids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "iqHUE2G5EpM0",
        "outputId": "d369df84-d088-4104-ccb5-5e110654b1e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Building an exciting new project with LangChain - come check it out! [{'source': 'tweet', '_id': 'fb93846a-2e7f-4d72-bd91-3ce597747b2c', '_collection_name': 'my_documents'}]\n",
            "* LangGraph is the best framework for building stateful, agentic applications! [{'source': 'tweet', '_id': 'fefb4b10-f6d6-4ce3-883a-1756d98a1dfd', '_collection_name': 'my_documents'}]\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "this code searches a Qdrant vector database\n",
        "for the two documents most similar to the query\n",
        "\"LangChain provides abstractions to make working\n",
        "with LLMs easy\" and then prints the content and\n",
        "metadata of these documents.\n",
        "\"\"\"\n",
        "results = qdrant.similarity_search(\n",
        "    \"LangChain provides abstractions to make working with LLMs easy\", k=2\n",
        ")\n",
        "for res in results:\n",
        "    print(f\"* {res.page_content} [{res.metadata}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TUkTIkkSJcbC",
        "outputId": "8f0b1641-1098-44ec-c0a8-00c906254a53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "found_docs_with_score\n",
            "* [SIM=0.611811] The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees. [{'source': 'news', '_id': '57d2b4c9-c8e3-4166-bb7c-27205bade645', '_collection_name': 'my_documents'}]\n"
          ]
        }
      ],
      "source": [
        "from langchain_qdrant import RetrievalMode\n",
        "\"\"\"\n",
        "this code block sets up a connection to a Qdrant vector\n",
        "database, prepares to store documents there as vectors\n",
        "using the Hugging Face embeddings model and creates an\n",
        "empty list to fill with documents in further steps.\n",
        "\"\"\"\n",
        "qdrant = QdrantVectorStore.from_documents(\n",
        "    docs,\n",
        "    embedding=embeddings,\n",
        "    url=url,\n",
        "    api_key=api_key,\n",
        "    prefer_grpc=True,\n",
        "    collection_name=\"my_documents\",\n",
        "    retrieval_mode=RetrievalMode.DENSE,\n",
        ")\n",
        "\n",
        "print(\"found_docs_with_score\")\n",
        "query = \"Will it be hot tomorrow\"\n",
        "results = qdrant.similarity_search_with_score(query, k=1)\n",
        "\n",
        "for doc, score in results:\n",
        "    print(f\"* [SIM={score:3f}] {doc.page_content} [{doc.metadata}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_LIn5m0-QAdg",
        "outputId": "173f9fb6-3427-4dd4-d8ea-2258b96b22d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* The top 10 soccer players in the world right now. [{'source': 'website', '_id': '0e8b4493-60d6-41b6-b734-14330631c897', '_collection_name': 'my_documents'}]\n"
          ]
        }
      ],
      "source": [
        "from qdrant_client import models\n",
        "\n",
        "\"\"\"\n",
        "This code snippet is searching for documents\n",
        "related to \"Who are the best soccer players in\n",
        "the world?\" but it's adding an extra condition:\n",
        "it only wants documents that contain the exact phrase\n",
        "\"The top 10 soccer players in the world right now.\"\n",
        "in their content. Then, it prints the content and\n",
        "source of the matching document. It's essentially performing\n",
        "a targeted search within the vector database\n",
        "\"\"\"\n",
        "results = qdrant.similarity_search(\n",
        "    query=\"Who are the best soccer players in the world?\",\n",
        "    k=1,\n",
        "    filter=models.Filter(\n",
        "        should=[\n",
        "            models.FieldCondition(\n",
        "                key=\"page_content\",\n",
        "                match=models.MatchValue(\n",
        "                    value=\"The top 10 soccer players in the world right now.\"\n",
        "                ),\n",
        "            ),\n",
        "        ]\n",
        "    ),\n",
        ")\n",
        "for doc in results:\n",
        "    print(f\"* {doc.page_content} [{doc.metadata}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "JJuRxqQXQe9N",
        "outputId": "d0b0e24b-c3c8-4e13-a8df-79cf0e1b1b59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'tweet', '_id': 'fb93846a-2e7f-4d72-bd91-3ce597747b2c', '_collection_name': 'my_documents'}, page_content='Building an exciting new project with LangChain - come check it out!'),\n",
              " Document(metadata={'source': 'tweet', '_id': 'fefb4b10-f6d6-4ce3-883a-1756d98a1dfd', '_collection_name': 'my_documents'}, page_content='LangGraph is the best framework for building stateful, agentic applications!')]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "this code takes a query, uses a similarity search\n",
        "to find the 2 most relevant documents in your database,\n",
        "and then likely returns those documents.\n",
        "\"\"\"\n",
        "retriever = qdrant.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2})\n",
        "retriever.invoke(\"LangChain provides abstractions to make working with LLMs easy\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
